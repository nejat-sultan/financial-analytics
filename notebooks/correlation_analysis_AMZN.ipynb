{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daf0e997-36cc-4daa-b918-48d7386a2675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Data:\n",
      "                Open      High       Low     Close  Adj Close      Volume  \\\n",
      "Date                                                                        \n",
      "1997-05-15  0.121875  0.125000  0.096354  0.097917   0.097917  1443120000   \n",
      "1997-05-16  0.098438  0.098958  0.085417  0.086458   0.086458   294000000   \n",
      "1997-05-19  0.088021  0.088542  0.081250  0.085417   0.085417   122136000   \n",
      "1997-05-20  0.086458  0.087500  0.081771  0.081771   0.081771   109344000   \n",
      "1997-05-21  0.081771  0.082292  0.068750  0.071354   0.071354   377064000   \n",
      "\n",
      "            Dividends  Stock Splits  \n",
      "Date                                 \n",
      "1997-05-15        0.0           0.0  \n",
      "1997-05-16        0.0           0.0  \n",
      "1997-05-19        0.0           0.0  \n",
      "1997-05-20        0.0           0.0  \n",
      "1997-05-21        0.0           0.0  \n",
      "\n",
      "News Data:\n",
      "                           Unnamed: 0  \\\n",
      "date                                    \n",
      "2020-06-05 10:30:54-04:00           0   \n",
      "2020-06-03 10:45:20-04:00           1   \n",
      "2020-05-26 04:30:07-04:00           2   \n",
      "2020-05-22 12:45:06-04:00           3   \n",
      "2020-05-22 11:38:59-04:00           4   \n",
      "\n",
      "                                                                    headline  \\\n",
      "date                                                                           \n",
      "2020-06-05 10:30:54-04:00            Stocks That Hit 52-Week Highs On Friday   \n",
      "2020-06-03 10:45:20-04:00         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2020-05-26 04:30:07-04:00                      71 Biggest Movers From Friday   \n",
      "2020-05-22 12:45:06-04:00       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "2020-05-22 11:38:59-04:00  B of A Securities Maintains Neutral on Agilent...   \n",
      "\n",
      "                                                                         url  \\\n",
      "date                                                                           \n",
      "2020-06-05 10:30:54-04:00  https://www.benzinga.com/news/20/06/16190091/s...   \n",
      "2020-06-03 10:45:20-04:00  https://www.benzinga.com/news/20/06/16170189/s...   \n",
      "2020-05-26 04:30:07-04:00  https://www.benzinga.com/news/20/05/16103463/7...   \n",
      "2020-05-22 12:45:06-04:00  https://www.benzinga.com/news/20/05/16095921/4...   \n",
      "2020-05-22 11:38:59-04:00  https://www.benzinga.com/news/20/05/16095304/b...   \n",
      "\n",
      "                                   publisher stock  \n",
      "date                                                \n",
      "2020-06-05 10:30:54-04:00  Benzinga Insights     A  \n",
      "2020-06-03 10:45:20-04:00  Benzinga Insights     A  \n",
      "2020-05-26 04:30:07-04:00         Lisa Levin     A  \n",
      "2020-05-22 12:45:06-04:00         Lisa Levin     A  \n",
      "2020-05-22 11:38:59-04:00         Vick Meyer     A  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def load_and_prepare_data(stock_file, news_file):\n",
    "    stock_data = pd.read_csv(stock_file, parse_dates=['Date'])\n",
    "    news_data = pd.read_csv(news_file, parse_dates=['date'])\n",
    "\n",
    "    stock_data.set_index('Date', inplace=True)\n",
    "    news_data.set_index('date', inplace=True)\n",
    "\n",
    "    return stock_data, news_data\n",
    "\n",
    "stock_file = 'C:/Users/nejat/AIM Projects/week1 data/yfinance_data/AMZN_historical_data.csv'\n",
    "news_file = 'C:/Users/nejat/AIM Projects/week1 data/raw_analyst_ratings/raw_analyst_ratings.csv'\n",
    "stock_data, news_data = load_and_prepare_data(stock_file, news_file)\n",
    "\n",
    "print(\"Stock Data:\")\n",
    "print(stock_data.head())  \n",
    "\n",
    "print(\"\\nNews Data:\")\n",
    "print(news_data.head()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "692c5edf-766f-46a2-9419-ad93f3ec7b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "News Data with Sentiment (Sample):\n",
      "                                                              headline  \\\n",
      "date                                                                     \n",
      "2011-07-07 00:00:00       EXCO Resources Spiking Lower on Heavy Volume   \n",
      "2015-12-22 00:00:00                   Benzinga's Top #PreMarket Losers   \n",
      "2020-01-27 00:00:00  DPW Holdings Announces That It has Finalized t...   \n",
      "2012-07-16 00:00:00                     Earnings Scheduled For July 16   \n",
      "2011-07-06 00:00:00      Five Forex ETFs Your Broker Forgot To Mention   \n",
      "\n",
      "                     Sentiment  \n",
      "date                            \n",
      "2011-07-07 00:00:00      -0.20  \n",
      "2015-12-22 00:00:00       0.15  \n",
      "2020-01-27 00:00:00       0.10  \n",
      "2012-07-16 00:00:00       0.00  \n",
      "2011-07-06 00:00:00       0.00  \n"
     ]
    }
   ],
   "source": [
    "def perform_sentiment_analysis(news_data, sample_size=100):\n",
    "    def get_sentiment(text):\n",
    "        analysis = TextBlob(text)\n",
    "        return analysis.sentiment.polarity  \n",
    "\n",
    "    if news_data is None or news_data.empty:\n",
    "        print(\"Error: news_data is either None or empty.\")\n",
    "        return None\n",
    "    \n",
    "    sample_size = min(sample_size, len(news_data))\n",
    "    news_data_sample = news_data.sample(sample_size)\n",
    "    \n",
    "    news_data_sample['Sentiment'] = news_data_sample['headline'].apply(get_sentiment)\n",
    "    \n",
    "    print(\"\\nNews Data with Sentiment (Sample):\")\n",
    "    print(news_data_sample[['headline', 'Sentiment']].head())\n",
    "    \n",
    "    return news_data_sample\n",
    "    \n",
    "news_data_sample = perform_sentiment_analysis(news_data, sample_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dee81ea-faaa-40b2-9f96-dc105774095d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stock Data with Daily Returns:\n",
      "                Open      High       Low     Close  Adj Close      Volume  \\\n",
      "Date                                                                        \n",
      "1997-05-15  0.121875  0.125000  0.096354  0.097917   0.097917  1443120000   \n",
      "1997-05-16  0.098438  0.098958  0.085417  0.086458   0.086458   294000000   \n",
      "1997-05-19  0.088021  0.088542  0.081250  0.085417   0.085417   122136000   \n",
      "1997-05-20  0.086458  0.087500  0.081771  0.081771   0.081771   109344000   \n",
      "1997-05-21  0.081771  0.082292  0.068750  0.071354   0.071354   377064000   \n",
      "\n",
      "            Dividends  Stock Splits  Daily_Returns  \n",
      "Date                                                \n",
      "1997-05-15        0.0           0.0            NaN  \n",
      "1997-05-16        0.0           0.0      -0.117028  \n",
      "1997-05-19        0.0           0.0      -0.012040  \n",
      "1997-05-20        0.0           0.0      -0.042685  \n",
      "1997-05-21        0.0           0.0      -0.127392  \n"
     ]
    }
   ],
   "source": [
    "def calculate_daily_returns(stock_data):\n",
    "    if stock_data is None:\n",
    "        raise ValueError(\"stock_data is None. Please check the data loading function.\")\n",
    "    \n",
    "    stock_data['Daily_Returns'] = stock_data['Close'].pct_change()\n",
    "    print(\"\\nStock Data with Daily Returns:\")\n",
    "    print(stock_data.head())\n",
    "    \n",
    "    return stock_data\n",
    "\n",
    "stock_data = calculate_daily_returns(stock_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d653af-3391-433a-a352-bb7a4ce1afae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Daily Sentiment Scores:\n",
      "                  Date  Avg_Sentiment\n",
      "0  2010-03-15 00:00:00            0.0\n",
      "1  2010-07-09 00:00:00            0.0\n",
      "2  2010-08-09 00:00:00            0.0\n",
      "3  2010-09-09 00:00:00            0.0\n",
      "4  2010-12-15 00:00:00            0.3\n"
     ]
    }
   ],
   "source": [
    "def aggregate_daily_sentiment(news_data_sample):\n",
    "    if 'Sentiment' not in news_data_sample.columns:\n",
    "        print(\"Error: 'Sentiment' column is missing.\")\n",
    "        return None\n",
    "\n",
    "    avg_daily_sentiment = news_data_sample.groupby(news_data_sample.index)['Sentiment'].mean().reset_index()\n",
    "    avg_daily_sentiment.columns = ['Date', 'Avg_Sentiment']\n",
    "    print(\"\\nAverage Daily Sentiment Scores:\")\n",
    "    print(avg_daily_sentiment.head())\n",
    "    \n",
    "    return avg_daily_sentiment\n",
    "    \n",
    "avg_daily_sentiment = aggregate_daily_sentiment(news_data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f456a31-2716-42f1-9254-fd82f3b7a826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged Data:\n",
      "        Date  Daily_Returns  Avg_Sentiment\n",
      "0 2010-03-15      -0.005234            0.0\n",
      "1 2010-07-09       0.008949            0.0\n",
      "2 2010-08-09       0.003974            0.0\n",
      "3 2010-09-09       0.008912            0.0\n",
      "4 2010-12-15       0.009371            0.3\n"
     ]
    }
   ],
   "source": [
    "def merge_stock_sentiment(stock_data, avg_daily_sentiment):\n",
    "    stock_data = stock_data.reset_index().rename(columns={'Date': 'Date'})\n",
    "    avg_daily_sentiment = avg_daily_sentiment.rename(columns={'index': 'Date', 'Sentiment': 'Avg_Sentiment'})\n",
    "\n",
    "    stock_data['Date'] = pd.to_datetime(stock_data['Date'], errors='coerce')\n",
    "    avg_daily_sentiment['Date'] = pd.to_datetime(avg_daily_sentiment['Date'], errors='coerce')\n",
    "\n",
    "    stock_data.dropna(subset=['Date'], inplace=True)\n",
    "    avg_daily_sentiment.dropna(subset=['Date'], inplace=True)\n",
    "\n",
    "    merged_data = pd.merge(stock_data[['Date', 'Daily_Returns']], avg_daily_sentiment[['Date', 'Avg_Sentiment']], on='Date', how='inner')\n",
    "    print(\"\\nMerged Data:\")\n",
    "    print(merged_data.head())\n",
    "    \n",
    "    return merged_data \n",
    "\n",
    "merged_data = merge_stock_sentiment(stock_data, avg_daily_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae4772b7-cb6c-4356-92e3-3d76cbec60f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlation Analysis:\n",
      "Pearson Correlation Coefficient: 0.1171\n",
      "P-value: 0.2507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.11712840647562921, 0.25072367709026766)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def correlation_analysis(merged_data):\n",
    "    if 'Daily_Returns' not in merged_data.columns or 'Avg_Sentiment' not in merged_data.columns:\n",
    "        raise ValueError(\"Merged data is missing required columns.\")\n",
    "    \n",
    "    correlation, p_value = pearsonr(merged_data['Daily_Returns'].dropna(), merged_data['Avg_Sentiment'].dropna())\n",
    "    \n",
    "    print(\"\\nCorrelation Analysis:\")\n",
    "    print(f\"Pearson Correlation Coefficient: {correlation:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    \n",
    "    return correlation, p_value\n",
    "\n",
    "correlation_analysis(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bef2ac-c450-44c0-8f51-032eb827656d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
